

@incollection{suk_brain_2019,
	location = {Cham},
	title = {Brain {MR} Image Segmentation in Small Dataset with Adversarial Defense and Task Reorganization},
	volume = {11861},
	isbn = {978-3-030-32691-3 978-3-030-32692-0},
	url = {http://link.springer.com/10.1007/978-3-030-32692-0_1},
	abstract = {Medical image segmentation is challenging especially in dealing with small dataset of 3D {MR} images. Encoding the variation of brain anatomical structures from individual subjects cannot be easily achieved, which is further challenged by only a limited number of well labeled subjects for training. In this study, we aim to address the issue of brain {MR} image segmentation in small dataset. First, concerning the limited number of training images, we adopt adversarial defense to augment the training data and therefore increase the robustness of the network. Second, inspired by the prior knowledge of neural anatomies, we reorganize the segmentation tasks of different regions into several groups in a hierarchical way. Third, the task reorganization extends to the semantic level, as we incorporate an additional object-level classification task to contribute highorder visual features toward the pixel-level segmentation task. In experiments we validate our method by segmenting gray matter, white matter, and several major regions on a challenge dataset. The proposed method with only seven subjects for training can achieve 84.46\% of Dice score in the onsite test set.},
	pages = {1--8},
	booktitle = {Machine Learning in Medical Imaging},
	publisher = {Springer International Publishing},
	author = {Ren, Xuhua and Zhang, Lichi and Wei, Dongming and Shen, Dinggang and Wang, Qian},
	editor = {Suk, Heung-Il and Liu, Mingxia and Yan, Pingkun and Lian, Chunfeng},
	urldate = {2020-05-28},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-32692-0_1},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Brain MR Image Segmentation in Small Dataset with Adversarial Defense and Task Reorganization.pdf:/Users/tianyangsun/Desktop/Paper archive/Brain MR Image Segmentation in Small Dataset with Adversarial Defense and Task Reorganization.pdf:application/pdf}
}

@article{roy_squeeze_2019,
	title = {'Squeeze \& Excite' Guided Few-Shot Segmentation of Volumetric Images},
	url = {http://arxiv.org/abs/1902.01314},
	abstract = {Deep neural networks enable highly accurate image segmentation, but require large amounts of manually annotated data for supervised training. Few-shot learning aims to address this shortcoming by learning a new class from a few annotated support examples. We introduce, a novel few-shot framework, for the segmentation of volumetric medical images with only a few annotated slices. Compared to other related works in computer vision, the major challenges are the absence of pre-trained networks and the volumetric nature of medical scans. We address these challenges by proposing a new architecture for few-shot segmentation that incorporates ‘squeeze \& excite’ blocks. Our two-armed architecture consists of a conditioner arm, which processes the annotated support input and generates a task-speciﬁc representation. This representation is passed on to the segmenter arm that uses this information to segment the new query image. To facilitate eﬃcient interaction between the conditioner and the segmenter arm, we propose to use ‘channel squeeze \& spatial excitation’ blocks – a light-weight computational module – that enables heavy interaction between both the arms with negligible increase in model complexity. This contribution allows us to perform image segmentation without relying on a pre-trained model, which generally is unavailable for medical scans. Furthermore, we propose an eﬃcient strategy for volumetric segmentation by optimally pairing a few slices of the support volume to all the slices of the query volume. We perform experiments for organ segmentation on whole-body contrast-enhanced {CT} scans from the Visceral Dataset. Our proposed model outperforms multiple baselines and existing approaches with respect to the segmentation accuracy by a signiﬁcant margin. The source code is available at https://github.com/abhi4ssj/few-shot-segmentation.},
	journaltitle = {{arXiv}:1902.01314 [cs]},
	author = {Roy, Abhijit Guha and Siddiqui, Shayan and Pölsterl, Sebastian and Navab, Nassir and Wachinger, Christian},
	urldate = {2020-05-28},
	date = {2019-10-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1902.01314},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {‘Squeeze & Excite’ Guided Few-Shot Segmentation of Volumetric Images.pdf:/Users/tianyangsun/Desktop/Paper archive/‘Squeeze & Excite’ Guided Few-Shot Segmentation of Volumetric Images.pdf:application/pdf}
}

@inproceedings{shaban_one-shot_2017,
	location = {London, {UK}},
	title = {One-Shot Learning for Semantic Segmentation},
	isbn = {978-1-901725-60-5},
	url = {http://www.bmva.org/bmvc/2017/papers/paper167/index.html},
	doi = {10.5244/C.31.167},
	abstract = {Low-shot learning methods for image classiﬁcation support learning from sparse data. We extend these techniques to support dense semantic image segmentation. Speciﬁcally, we train a network that, given a small set of annotated images, produces parameters for a Fully Convolutional Network ({FCN}). We use this {FCN} to perform dense pixel-level prediction on a test image for the new semantic class. Our architecture shows a 25\% relative {meanIoU} improvement compared to the best baseline methods for one-shot segmentation on unseen classes in the {PASCAL} {VOC} 2012 dataset and is at least 3× faster.},
	eventtitle = {British Machine Vision Conference 2017},
	pages = {167},
	booktitle = {Procedings of the British Machine Vision Conference 2017},
	publisher = {British Machine Vision Association},
	author = {Shaban, Amirreza and Bansal, Shray and Liu, Zhen and Essa, Irfan and Boots, Byron},
	urldate = {2020-05-27},
	date = {2017},
	langid = {english},
	file = {One-Shot Learning for Semantic Segmentation.pdf:/Users/tianyangsun/Desktop/Paper archive/One-Shot Learning for Semantic Segmentation.pdf:application/pdf}
}

@article{rakelly_few-shot_nodate,
	title = {Few-Shot Segmentation Propagation with Guided Networks},
	abstract = {Learning-based methods for visual segmentation have made progress on particular types of segmentation tasks, but are limited by the necessary supervision, the narrow deﬁnitions of ﬁxed tasks, and the lack of control during inference for correcting errors. To remedy the rigidity and annotation burden of standard approaches, we address the problem of few-shot segmentation: given few image and few pixel supervision, segment any images accordingly. We propose guided networks, which extract a latent task representation from any amount of supervision, and optimize our architecture end-to-end for fast, accurate few-shot segmentation. Our method can switch tasks without further optimization and quickly update when given more guidance. We report the ﬁrst results for segmentation from one pixel per concept and show real-time interactive video segmentation. Our uniﬁed approach propagates pixel annotations across space for interactive segmentation, across time for video segmentation, and across scenes for semantic segmentation. Our guided segmentor is state-of-the-art in accuracy for the amount of annotation and time. See http://github.com/shelhamer/revolver for code, models, and more details.},
	pages = {10},
	author = {Rakelly, Kate and Shelhamer, Evan and Darrell, Trevor and Efros, Alexei and Levine, Sergey},
	langid = {english},
	file = {Few-Shot Segmentation Propagation with Guided Networks.pdf:/Users/tianyangsun/Desktop/Paper archive/Few-Shot Segmentation Propagation with Guided Networks.pdf:application/pdf}
}

@article{hussein_risk_2017,
	title = {Risk Stratification of Lung Nodules Using 3D {CNN}-Based Multi-task Learning},
	volume = {10265},
	url = {http://arxiv.org/abs/1704.08797},
	doi = {10.1007/978-3-319-59050-9_20},
	abstract = {Risk stratiﬁcation of lung nodules is a task of primary importance in lung cancer diagnosis. Any improvement in robust and accurate nodule characterization can assist in identifying cancer stage, prognosis, and improving treatment planning. In this study, we propose a 3D Convolutional Neural Network ({CNN}) based nodule characterization strategy. With a completely 3D approach, we utilize the volumetric information from a {CT} scan which would be otherwise lost in the conventional 2D {CNN} based approaches. In order to address the need for a large amount for training data for {CNN}, we resort to transfer learning to obtain highly discriminative features. Moreover, we also acquire the task dependent feature representation for six high-level nodule attributes and fuse this complementary information via a Multi-task learning ({MTL}) framework. Finally, we propose to incorporate potential disagreement among radiologists while scoring diﬀerent nodule attributes in a graph regularized sparse multi-task learning. We evaluated our proposed approach on one of the largest publicly available lung nodule datasets comprising 1018 scans and obtained state-of-the-art results in regressing the malignancy scores.},
	pages = {249--260},
	journaltitle = {{arXiv}:1704.08797 [cs]},
	author = {Hussein, Sarfaraz and Cao, Kunlin and Song, Qi and Bagci, Ulas},
	urldate = {2020-05-27},
	date = {2017},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1704.08797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning.pdf:/Users/tianyangsun/Desktop/Paper archive/Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning.pdf:application/pdf}
}
@article{wang_generalizing_2020,
	title = {Generalizing from a Few Examples: A Survey on Few-Shot Learning},
	url = {http://arxiv.org/abs/1904.05046},
	shorttitle = {Generalizing from a Few Examples},
	abstract = {Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-Shot Learning ({FSL}) is proposed to tackle this problem. Using prior knowledge, {FSL} can rapidly generalize to new tasks containing only a few samples with supervised information. In this paper, we conduct a thorough survey to fully understand {FSL}. Starting from a formal definition of {FSL}, we distinguish {FSL} from several relevant machine learning problems. We then point out that the core issue in {FSL} is that the empirical risk minimized is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize {FSL} methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the {FSL} problem setups, techniques, applications and theories, are also proposed to provide insights for future research.},
	journaltitle = {{arXiv}:1904.05046 [cs]},
	author = {Wang, Yaqing and Yao, Quanming and Kwok, James and Ni, Lionel M.},
	urldate = {2020-05-12},
	date = {2020-03-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.05046},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Few-shot Learning\: A Survey.pdf:/Users/tianyangsun/Desktop/Paper archive/Few-shot Learning\: A Survey.pdf:application/pdf}
}

@article{gao_low-shot_nodate,
	title = {Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks},
	abstract = {Deep neural networks suffer from over-ﬁtting and catastrophic forgetting when trained with small data. One natural remedy for this problem is data augmentation, which has been recently shown to be effective. However, previous works either assume that intra-class variances can always be generalized to new classes, or employ naive generation methods to hallucinate ﬁnite examples without modeling their latent distributions. In this work, we propose Covariance-Preserving Adversarial Augmentation Networks to overcome existing limits of low-shot learning. Speciﬁcally, a novel Generative Adversarial Network is designed to model the latent distribution of each novel class given its related base counterparts. Since direct estimation of novel classes can be inductively biased, we explicitly preserve covariance information as the “variability” of base examples during the generation process. Empirical results show that our model can generate realistic yet diverse examples, leading to substantial improvements on the {ImageNet} benchmark over the state of the art.},
	pages = {11},
	author = {Gao, Hang and Shou, Zheng and Zareian, Alireza and Zhang, Hanwang and Chang, Shih-Fu},
	langid = {english},
	file = {Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks.pdf:/Users/tianyangsun/Desktop/Paper archive/Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks.pdf:application/pdf}
}

@article{douze_low-shot_2018,
	title = {Low-shot learning with large-scale diffusion},
	url = {http://arxiv.org/abs/1706.02332},
	abstract = {This paper considers the problem of inferring image labels from images when only a few annotated examples are available at training time. This setup is often referred to as low-shot learning, where a standard approach is to retrain the last few layers of a convolutional neural network learned on separate classes for which training examples are abundant. We consider a semi-supervised setting based on a large collection of images to support label propagation. This is possible by leveraging the recent advances on largescale similarity graph construction.},
	journaltitle = {{arXiv}:1706.02332 [cs, stat]},
	author = {Douze, Matthijs and Szlam, Arthur and Hariharan, Bharath and Jégou, Hervé},
	urldate = {2020-05-12},
	date = {2018-06-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1706.02332},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Low-shot learning with large-scale diffusion.pdf:/Users/tianyangsun/Desktop/Paper archive/Low-shot learning with large-scale diffusion.pdf:application/pdf}
}

@incollection{ferrari_fine-grained_2018,
	location = {Cham},
	title = {Fine-Grained Visual Categorization Using Meta-learning Optimization with Sample Selection of Auxiliary Data},
	volume = {11212},
	isbn = {978-3-030-01236-6 978-3-030-01237-3},
	url = {http://link.springer.com/10.1007/978-3-030-01237-3_15},
	abstract = {Fine-grained visual categorization ({FGVC}) is challenging due in part to the fact that it is often diﬃcult to acquire an enough number of training samples. To employ large models for {FGVC} without suﬀering from overﬁtting, existing methods usually adopt a strategy of pretraining the models using a rich set of auxiliary data, followed by ﬁnetuning on the target {FGVC} task. However, the objective of pre-training does not take the target task into account, and consequently such obtained models are suboptimal for ﬁne-tuning. To address this issue, we propose in this paper a new deep {FGVC} model termed {MetaFGNet}. Training of {MetaFGNet} is based on a novel regularized meta-learning objective, which aims to guide the learning of network parameters so that they are optimal for adapting to the target {FGVC} task. Based on {MetaFGNet}, we also propose a simple yet eﬀective scheme for selecting more useful samples from the auxiliary data. Experiments on benchmark {FGVC} datasets show the eﬃcacy of our proposed method.},
	pages = {241--256},
	booktitle = {Computer Vision – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Zhang, Yabin and Tang, Hui and Jia, Kui},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	urldate = {2020-05-12},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-030-01237-3_15},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Fine-Grained Visual Categorization using Meta-Learning Optimization with Sample Selection of Auxiliary Data.pdf:/Users/tianyangsun/Desktop/Paper archive/Fine-Grained Visual Categorization using Meta-Learning Optimization with Sample Selection of Auxiliary Data.pdf:application/pdf}
}

@article{tajbakhsh_embracing_2020,
	title = {Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation},
	volume = {63},
	issn = {13618415},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S136184152030058X},
	doi = {10.1016/j.media.2020.101693},
	shorttitle = {Embracing imperfect datasets},
	abstract = {The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the ﬁeld of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the beneﬁts and requirements of the surveyed methodologies and provide our recommended solutions. We hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets.},
	pages = {101693},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Tajbakhsh, Nima and Jeyaseelan, Laura and Li, Qian and Chiang, Jeffrey N. and Wu, Zhihao and Ding, Xiaowei},
	urldate = {2020-05-20},
	date = {2020-07},
	langid = {english},
	file = {Embracing imperfect datasets\: A review of deep learning solutions for medical image segmentation.pdf:/Users/tianyangsun/Desktop/Paper archive/Embracing imperfect datasets\: A review of deep learning solutions for medical image segmentation.pdf:application/pdf}
}

@incollection{wang_improving_2019,
	location = {Cham},
	title = {Improving Pathological Structure Segmentation via Transfer Learning Across Diseases},
	volume = {11795},
	isbn = {978-3-030-33390-4 978-3-030-33391-1},
	url = {http://link.springer.com/10.1007/978-3-030-33391-1_11},
	abstract = {One of the biggest challenges in developing robust machine learning techniques for medical image analysis is the lack of access to large-scale annotated image datasets needed for supervised learning. When the task is to segment pathological structures (e.g. lesions, tumors) from patient images, training on a dataset with few samples is very challenging due to the large class imbalance and inter-subject variability. In this paper, we explore how to best leverage a segmentation model that has been pre-trained on a large dataset of patients images with one disease in order to successfully train a deep learning pathology segmentation model for a diﬀerent disease, for which only a relatively small patient dataset is available. Speciﬁcally, we train a {UNet} model on a large-scale, proprietary, multi-center, multi-scanner Multiple Sclerosis ({MS}) clinical trial dataset containing over 3500 multi-modal {MRI} samples with expertderived lesion labels. We explore several transfer learning approaches to leverage the learned {MS} model for the task of multi-class brain tumor segmentation on the {BraTS} 2018 dataset. Our results indicate that adapting and ﬁne-tuning the encoder and decoder of the network trained on the larger {MS} dataset leads to improvement in brain tumor segmentation when few instances are available. This type of transfer learning outperforms training and testing the network on the {BraTS} dataset from scratch as well as several other transfer learning approaches, particularly when only a small subset of the dataset is available.},
	pages = {90--98},
	booktitle = {Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data},
	publisher = {Springer International Publishing},
	author = {Kaur, Barleen and Lemaître, Paul and Mehta, Raghav and Sepahvand, Nazanin Mohammadi and Precup, Doina and Arnold, Douglas and Arbel, Tal},
	editor = {Wang, Qian and Milletari, Fausto and Nguyen, Hien V. and Albarqouni, Shadi and Cardoso, M. Jorge and Rieke, Nicola and Xu, Ziyue and Kamnitsas, Konstantinos and Patel, Vishal and Roysam, Badri and Jiang, Steve and Zhou, Kevin and Luu, Khoa and Le, Ngan},
	urldate = {2020-05-23},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-33391-1_11},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Improving Pathological Structure Segmentation via Transfer Learning Across Diseases.pdf:/Users/tianyangsun/Desktop/Paper archive/Improving Pathological Structure Segmentation via Transfer Learning Across Diseases.pdf:application/pdf}
}

@article{zhang_when_2019,
	title = {When Unseen Domain Generalization is Unnecessary? Rethinking Data Augmentation},
	url = {http://arxiv.org/abs/1906.03347},
	shorttitle = {When Unseen Domain Generalization is Unnecessary?},
	abstract = {Recent advances in deep learning for medical image segmentation demonstrate expert-level accuracy. However, in clinically realistic environments, such methods have marginal performance due to differences in image domains, including different imaging protocols, device vendors and patient populations. Here we consider the problem of domain generalization, when a model is trained once, and its performance generalizes to unseen domains. Intuitively, within a speciﬁc medical imaging modality the domain differences are smaller relative to natural images domain variability. We rethink data augmentation for medical 3D images and propose a deep stacked transformations ({DST}) approach for domain generalization. Speciﬁcally, a series of n stacked transformations are applied to each image in each mini-batch during network training to account for the contribution of domain-speciﬁc shifts in medical images. We comprehensively evaluate our method on three tasks: segmentation of whole prostate from 3D {MRI}, left atrial from 3D {MRI}, and left ventricle from 3D ultrasound. We demonstrate that when trained on a small source dataset, (i) on average, {DST} models on unseen datasets degrade only by 11\% (Dice score change), compared to the conventional augmentation (degrading 39\%) and {CycleGAN}-based domain adaptation method (degrading 25\%), (ii) when evaluation on the same domain, {DST} is also better albeit only marginally. (iii) When training on large-sized data, {DST} on unseen domains reaches performance of state-of-the-art fully supervised models. These ﬁndings establish a strong benchmark for the study of domain generalization in medical imaging, and can be generalized to the design of robust deep segmentation models for clinical deployment.},
	journaltitle = {{arXiv}:1906.03347 [cs, eess]},
	author = {Zhang, Ling and Wang, Xiaosong and Yang, Dong and Sanford, Thomas and Harmon, Stephanie and Turkbey, Baris and Roth, Holger and Myronenko, Andriy and Xu, Daguang and Xu, Ziyue},
	urldate = {2020-05-25},
	date = {2019-06-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.03347},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {When Unseen Domain Generalization is Unnecessary? Rethinking Data Augmentation.pdf:/Users/tianyangsun/Desktop/Paper archive/When Unseen Domain Generalization is Unnecessary? Rethinking Data Augmentation.pdf:application/pdf}
}

@inproceedings{panfilov_improving_2019,
	location = {Seoul, Korea (South)},
	title = {Improving Robustness of Deep Learning Based Knee {MRI} Segmentation: Mixup and Adversarial Domain Adaptation},
	isbn = {978-1-72815-023-9},
	url = {https://ieeexplore.ieee.org/document/9022164/},
	doi = {10.1109/ICCVW.2019.00057},
	shorttitle = {Improving Robustness of Deep Learning Based Knee {MRI} Segmentation},
	abstract = {Degeneration of articular cartilage ({AC}) is actively studied in knee osteoarthritis ({OA}) research via magnetic resonance imaging ({MRI}). Segmentation of {AC} tissues from {MRI} data is an essential step in quantiﬁcation of their damage. Deep learning ({DL}) based methods have shown potential in this realm and are the current state-of-the-art, however, their robustness to heterogeneity of {MRI} acquisition settings remains an open problem. In this study, we investigated two modern regularization techniques – mixup and adversarial unsupervised domain adaptation ({UDA}) – to improve the robustness of {DL}-based knee cartilage segmentation to new {MRI} acquisition settings. Our validation setup included two datasets produced by different {MRI} scanners and using distinct data acquisition protocols. We assessed the robustness of automatic segmentation by comparing mixup and {UDA} approaches to a strong baseline method at different {OA} severity stages and, additionally, in relation to anatomical locations. Our results showed that for moderate changes in knee {MRI} data acquisition settings both approaches may provide notable improvements in the robustness, which are consistent for all stages of the disease and affect the clinically important areas of the knee joint. However, mixup may be considered as a recommended approach, since it is more computationally efﬁcient and does not require additional data from the target acquisition setup.},
	eventtitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision Workshop ({ICCVW})},
	pages = {450--459},
	booktitle = {2019 {IEEE}/{CVF} International Conference on Computer Vision Workshop ({ICCVW})},
	publisher = {{IEEE}},
	author = {Panfilov, Egor and Tiulpin, Aleksei and Klein, Stefan and Nieminen, Miika T. and Saarakkala, Simo},
	urldate = {2020-05-26},
	date = {2019-10},
	langid = {english},
	file = {Improving Robustness of Deep Learning Based Knee MRI Segmentation\: Mixup and Adversarial Domain Adaptation.pdf:/Users/tianyangsun/Desktop/Paper archive/Improving Robustness of Deep Learning Based Knee MRI Segmentation\: Mixup and Adversarial Domain Adaptation.pdf:application/pdf}
}

@article{zhang_mixup_2018,
	title = {mixup: Beyond Empirical Risk Minimization},
	url = {http://arxiv.org/abs/1710.09412},
	shorttitle = {mixup},
	abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the {ImageNet}-2012, {CIFAR}-10, {CIFAR}-100, Google commands and {UCI} datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also ﬁnd that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
	journaltitle = {{arXiv}:1710.09412 [cs, stat]},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	urldate = {2020-05-26},
	date = {2018-04-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1710.09412},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {mixup\: BEYOND EMPIRICAL RISK MINIMIZATION.pdf:/Users/tianyangsun/Desktop/Paper archive/mixup\: BEYOND EMPIRICAL RISK MINIMIZATION.pdf:application/pdf}
}

@article{li_overfitting_2019,
	title = {Overfitting of neural nets under class imbalance: Analysis and improvements for segmentation},
	url = {http://arxiv.org/abs/1907.10982},
	shorttitle = {Overfitting of neural nets under class imbalance},
	abstract = {Overﬁtting in deep learning has been the focus of a number of recent works, yet its exact impact on the behavior of neural networks is not well understood. This study analyzes overﬁtting by examining how the distribution of logits alters in relation to how much the model overﬁts. Speciﬁcally, we ﬁnd that when training with few data samples, the distribution of logit activations when processing unseen test samples of an under-represented class tends to shift towards and even across the decision boundary, while the over-represented class seems unaﬀected. In image segmentation, foreground samples are often heavily under-represented. We observe that sensitivity of the model drops as a result of overﬁtting, while precision remains mostly stable. Based on our analysis, we derive asymmetric modiﬁcations of existing loss functions and regularizers including a large margin loss, focal loss, adversarial training and mixup, which speciﬁcally aim at reducing the shift observed when embedding unseen samples of the under-represented class. We study the case of binary segmentation of brain tumor core and show that our proposed simple modiﬁcations lead to signiﬁcantly improved segmentation performance over the symmetric variants.},
	journaltitle = {{arXiv}:1907.10982 [cs, stat]},
	author = {Li, Zeju and Kamnitsas, Konstantinos and Glocker, Ben},
	urldate = {2020-05-26},
	date = {2019-10-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.10982},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Overfitting of neural nets under class imbalance\: Analysis and improvements for segmentation .pdf:/Users/tianyangsun/Desktop/Paper archive/Overfitting of neural nets under class imbalance\: Analysis and improvements for segmentation .pdf:application/pdf}
}