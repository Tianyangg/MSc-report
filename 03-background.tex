
\section{Data augmentation}
In medical domain, huge dataset consists of large numbers of carefully labelled samples is rarely available due to heavy workload for annotations, rarity of disease, ethic issues of data acquire process and data privacy. Furthermore, different data acquire protocols (i.e. CT machines used by different hospitals) brings difficulties to clinical practice for good accuracy of existing pre-trained models. As a result, few shot learning and/or few shot segmentation has been explored in recent years. 
In this section, we focus on a few approaches that has been used in current literature which aim to explore the potential of existing training samples through various augmentation methods to alleviate the insufficient training samples in medical imaging. We discuss data augmentation method as well as the amount of data used in each work. Table \ref{} provide an overview of each method.

\subsection{Traditional Data Augmentation}
Traditional Data augmentation method in imaging domain refers to the process that does not require such training data to learn a transformation.\\

\cite{zhang_when_2019} investigated data augmentation methods under 3D medical domain of MR and ultrasound images. 
The data augmentation process consists of a sequence of traditional transformation techniques. The paper argued that sharpness in medical images during training process limits model generalization thus applying gaussian filter to images take noise into consideration. Brightness and contrast difference caused by variations in scanning protocols brings potential domain shift thus a sequenced random shift followed gamma correction and random linear transform in intensity are reasonable data augmentation methods. Finally spatial transformations including rotation, scaling and deformation is added to the augmentation process.
The source domain in this method is Prostate dataset \footnote{http://medicaldecathlon.com/index.html\#tasks} consists 48 4D volumes.
We argue here that the stacked transformation is physical transformation process independent to the size of dataset because no learning or training process is required in this augmentation method thus might bring benefits to our task. However we doubt the improvement due to the difference between CT and MR images.\\

%%%---------
Another method "mixup" by \cite{zhang_mixup_2018} based on generic vicinal distribution, which generates new samples through interpolation between two existing data. The author argued that this method works as a regularizer which encourages linear behavior between training samples. In terms of imaging, the augmentation is applied to CIFAR 10 (2D non medical) Dataset.
The work was originally implemented on training GANs. Later in medical domain, \cite{panfilov_improving_2019} further investigated mixup method on Knee MR images on OIA database \footnote{http://www.oai.ucsf/.edu/} that consists of 88 3D MRI scans. The work showed mixup improves generalization under their experiment setup while having risk of slight underfitting due to to the strong regularization. The author further mentioned not using weight decay in the experiment solve the underfitting issue.
\cite{tajbakhsh_embracing_2020} summarized mixup augmentation method gives "soft labels". Variations of the mixup method utilize asymmetric is further explored in \cite{li_overfitting_2019} trained on Brain MR images, and the method reports huge gain under their experiment setup.
We cannot guarantee the effectiveness of this augmentation method due to the domain difference between MRI and CT scans.

\subsection{Learning for augmentation}
Following the traditional augmentation methods, we here want to discuss a few medical image augmentation based on deep learning. Specifically we focus on those who used one or a few data during the augmentation which is close to the problem we are facing.\\

Adversarial defense was deployed in \cite{suk_brain_2019} for the augmentation of small samples in Brain MR segmentation. Adversarial samples generated though Fast Gradient Sign Method\cite{} and then added as training data to improve the robustness, which according the study in \cite{} without decreasing the performance. So far we believe this method worth trying because the experiment was trained on 7 brain volumes, which is close to our task.\\



\begin{tabular}{lllll}
\hline
Paper                                             & Method                        & Dataset              & Number of samples &  \\
\hline
\cite{zhang_when_2019}       & Stacked traditional transform & Prostate dataset     & 48 4D volumes     &  \\
\cite{zhang_mixup_2018}       & mixup                         & CIFAR 10             & Huge              &  \\
\cite{panfilov_improving_2019} & mixup                         & Knee MR images       & 88 3D MRI         &  \\
\cite{li_overfitting_2019}   & Asymmetric mixup              & BraTS ?              &                   &  \\
\cite{suk_brain_2019}                    & Adversarial defense           & MRBrainS18 challenge & 7 train, 14 test  &  \\
\hline
\end{tabular}




%
%\subsection{General Segmentation methods}
\section{Few shot learning in non-medical domain}
Recent work in non-medical few shot segmentation have explored several network structures that tend to provide correct segmentation for few labelled samples from dense to sparse annotations.\\

 Although few-shot learning for classification has been wide explored, and segmentation, in some sense, can be viewed as classification task,
 a direct extension from those networks might not give good results.\\
 
  Experiment of extending Siamese Network in meta learning classification to pixel-wise segmentation failed to scale well enough, but this idea inspire the work in \cite{shaban_one-shot_2017} that proposed a two-branch network for few-shot semantic segmentation. The work assumes that semantic class labels for training and testing have no overlap, that is $L_{train} \cap L_{test}= \varnothing$. Large dataset updates a pre-trained VGG network on ImageNet in the "conditioning branch", and a query sample updates the "segmentation branch" including a FCN-32 and a conv-fc7. The authors further utilize masking and weight hashing to combine the two branches. The experiment reported promising results in non medical dataset (PASCAL-5) the work further removed the effect of ImageNet and still show good performance. However, in our CT segmentation task, we might want to take 3D features into consideration.\\

Another work in \cite{rakelly_few-shot_nodate} relax the restriction of requiring dense segmentation masks to sparse annotations with similar backbone of VGG net. They utilize the guidance network that provide guiding inference to extract visual features through an encoder structure. The work is evaluated on both 2D images and video sets while the structure used in video sets.\\



\section{Few-shot learning in medical application}
\subsection{Transfer learning method}
In medical domain, few shot learning mainly focus on transfer learning from pre-trained networks that leverage both medical and non-medical datasets.\\

%Although recent machine learning community have seen a growing number of medical segmentation public dataset available, the amount of data samples is still less desirable compared to natural, non-medical datasets. Thus researchers have seek for methods that leverage natural images.\\

In Lung CT segmentation area, Sports-1M dataset has been used as source domain to train a multi-task learning model for nodule malignancy prediction and rating \cite{hussein_risk_2017}. The author reported significant improvement in the prediction accuracy, however, did not mention the proportion of data used for transfer training.\\

People tend to choose datasets from closer domain for transfer learning. It is reasonable to consider methods that transfer across disease in the same structure under the same modality. In our case, we might want to investigate transfer learning from NSCLC Dataset to Covid segmentation set given that both of them are lung CT scans.\\

Recent work explored several across disease transfer learning training techniques under MRI domain \cite{wang_improving_2019}. The paper evaluated three transfer learning methods trained on 3D U-Net by Fine tuning the last three layers, Fine tuning the decoder and Fine tuning all model parameters. 
The Source Dataset: Multiple Sclerosis Dataset consists 3630 MRI volumes and used Brain Tumor Dataset as Target dataset including 210 high-grade glioma (HGG) and 75 low-grade glioma (LGG) Brain MRI scans. The training target is a decaying weighted categorical cross entropy loss weighted by relative voxel. Their best validation performance of pre-trained network achieved validation performance AUC 0.77. Experiment result on 20, 50, 100 and 150 samples during Fine tuning respectively showed that Fine tuning all parameters out performed the rest methods in most cases.\\

One potential drawback is that compared to the our task, the target training set is relatively larger, the performance is expected to be less ideal when using "fine tune all" method using 4 or less volumes in our case.\\

Paper \cite{suk_brain_2019} trained segmentation of Brain MR image on 7 brain volumes after Adversarial defense augmentation. The work first split the segmentation from easy to hard into 2 individual classifiers then joint learning with dense pixel segmentation. The author reported that the result outperformed Unet and Vnet method trained from scratch. We argue that the augmentation provide good result in the segmentation accuracy while the segmentation part is not well explained in the paper. We have emailed the author for further details.

\subsection{Special network design}
Transfer learning methods usually require small samples to update millions of parameters that take the risk of overfitting \cite{shaban_one-shot_2017}. The design of multiple branch network, usually includes conditioner arm and segmentation arms inspired the deep learning in medical domain to go beyond transfer learning while encourage a stronger between-arms interaction to compensate the lacking in pre-trained model \cite{roy_squeeze_2019}. The proposed method perform 3D volume segmentation at test time while use 2D images during training. However the method requires start and end slice to be indicated for each query volume and still not achieving good dice score.

\begin{table}
\begin{tabular}{p{1cm} p{5cm} p{4cm} p{4cm}}
\hline
Paper    & Method                                & Domain Details                                          & Task                                       \\
\hline
{[}14{]} & Design Conditional Branch             & Target PASCAL-5        & Few shot segmentation                      \\
{[}15{]} & Guidance network                      & Target PASCAL VOC             & Few shot segmentation                      \\
{[}16{]} & Non medical to medical transfer       & Source: Sports-1M;  Target: Lung nodule                  & Multi-task learning: prediction and rating \\
{[}17{]} & Across domain transfer                & Source: MSD; Target: Brain Tumor Dataset & Segmentation                               \\
{[}13{]} & Augmentation+pixel dense segmentation & Only trained on 7 brain Volumes                         & Dense segmentation                         \\
{[}14{]} & Branch network design                 & --                                                      & Segmentation                               \\
\hline
\end{tabular}
\caption{Small sample methods in medical and non-medical domain}
\label{tab:small sample learning}
\end{table}	



